import sqlite3
import io
import csv
from utils import hard_cut
from google.cloud import bigquery
from google.oauth2 import service_account
import snowflake.connector
import json
import pandas as pd
from multiprocessing import Process, Queue
import threading

class SqlEnv:
    """
    SQL ì‹¤í–‰ í™˜ê²½ì„ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤
    - SQLite, Snowflake, BigQuery ë“± ë‹¤ì–‘í•œ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë° ì¿¼ë¦¬ ì‹¤í–‰ì„ ì§€ì›
    - ì—°ê²° í’€ë§ê³¼ íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬ ê¸°ëŠ¥ ì œê³µ
    """
    
    def __init__(self):
        """
        SqlEnv ì¸ìŠ¤í„´ìŠ¤ ì´ˆê¸°í™”
        - ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ë“¤ì„ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬ ìƒì„±
        """
        self.conns = {}  # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì„ ì €ì¥í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ {ê²½ë¡œ/ID: ì—°ê²°ê°ì²´}


    def get_rows(self, cursor, max_len):
        """
        ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ê²°ê³¼ì—ì„œ ì‹¤ì œ ë°ì´í„° í–‰ë“¤ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
        
        1. ì»¤ì„œ(cursor)ë€?
        - SQL ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•œ í›„ ê²°ê³¼ë¥¼ ê°€ë¦¬í‚¤ëŠ” í¬ì¸í„° ê°™ì€ ê²ƒ
        - ë§ˆì¹˜ íŒŒì¼ì„ ì½ì„ ë•Œ í˜„ì¬ ìœ„ì¹˜ë¥¼ ê°€ë¦¬í‚¤ëŠ” ê²ƒì²˜ëŸ¼, DB ê²°ê³¼ì—ì„œ í˜„ì¬ ì½ê³  ìˆëŠ” ìœ„ì¹˜ë¥¼ í‘œì‹œ
        - ì˜ˆ: SELECT * FROM users ì¿¼ë¦¬ ì‹¤í–‰ í›„, ê²°ê³¼ í…Œì´ë¸”ì˜ ê° ì¤„ì„ ìˆœì„œëŒ€ë¡œ ì½ì–´ì˜¬ ìˆ˜ ìˆê²Œ í•´ì¤Œ
        
        2. í–‰(row)ì´ë€?
        - í…Œì´ë¸”ì˜ í•œ ì¤„, ì¦‰ í•˜ë‚˜ì˜ ë ˆì½”ë“œë¥¼ ì˜ë¯¸
        - ì˜ˆ: ì‚¬ìš©ì í…Œì´ë¸”ì—ì„œ ("ê¹€ì² ìˆ˜", 25, "ì„œìš¸") ì´ëŸ° ì‹ìœ¼ë¡œ í•œ ì‚¬ëŒì˜ ì •ë³´ê°€ ë‹´ê¸´ í•œ ì¤„
        
        3. ì´ í•¨ìˆ˜ê°€ í•˜ëŠ” ì¼:
        - ì¿¼ë¦¬ ê²°ê³¼ í…Œì´ë¸”ì—ì„œ í•œ ì¤„ì”© ì½ì–´ì™€ì„œ ë¦¬ìŠ¤íŠ¸ë¡œ ëª¨ìŒ
        - ë‹¨, ê²°ê³¼ê°€ ë„ˆë¬´ í¬ë©´(max_len ì´ˆê³¼) ì¤‘ê°„ì— ë©ˆì¶¤ (ë©”ëª¨ë¦¬ ì ˆì•½)
        
        Args:
            cursor: SQL ì¿¼ë¦¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë‹´ê³  ìˆëŠ” ì»¤ì„œ ê°ì²´
            max_len (int): ê²°ê³¼ ë°ì´í„°ì˜ ìµœëŒ€ ë¬¸ìì—´ ê¸¸ì´ (ì˜ˆ: 30000ì)
            
        Returns:
            list: ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê°€ì ¸ì˜¨ í–‰ë“¤ì˜ ë¦¬ìŠ¤íŠ¸
                 ì˜ˆ: [("ê¹€ì² ìˆ˜", 25, "ì„œìš¸"), ("ì´ì˜í¬", 30, "ë¶€ì‚°"), ...]
        """
        rows = []           # ê°€ì ¸ì˜¨ í–‰ë“¤ì„ ì €ì¥í•  ë¹ˆ ë¦¬ìŠ¤íŠ¸
        current_len = 0     # í˜„ì¬ê¹Œì§€ ê°€ì ¸ì˜¨ ë°ì´í„°ì˜ ì´ ê¸¸ì´
        
        # ì»¤ì„œì—ì„œ í•œ í–‰ì”© ì½ì–´ì˜¤ê¸° (forë¬¸ìœ¼ë¡œ í•œ ì¤„ì”© ì²˜ë¦¬)
        for row in cursor:
            row_str = str(row)  # í–‰ì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•´ì„œ ê¸¸ì´ ì¸¡ì •
            rows.append(row)    # í–‰ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
            
            # ğŸ’¡ ë©”ëª¨ë¦¬ ë³´í˜¸: ë°ì´í„°ê°€ ë„ˆë¬´ ë§ìœ¼ë©´ ì¤‘ê°„ì— ë©ˆì¶¤
            # ì˜ˆ: 100ë§Œ ê°œ í–‰ì´ ìˆì–´ë„ 30,000ì ë¶„ëŸ‰ë§Œ ê°€ì ¸ì˜¤ê³  ë©ˆì¶¤
            if current_len + len(row_str) > max_len:
                break
            current_len += len(row_str)
        
        return rows


    def get_csv(self, columns, rows):
        """
        ì»¬ëŸ¼ê³¼ í–‰ ë°ì´í„°ë¥¼ CSV í˜•ì‹ì˜ ë¬¸ìì—´ë¡œ ë³€í™˜
        
        Args:
            columns (list): ì»¬ëŸ¼ëª… ë¦¬ìŠ¤íŠ¸
            rows (list): í–‰ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            
        Returns:
            str: CSV í˜•ì‹ì˜ ë¬¸ìì—´
        """
        output = io.StringIO()  # ë©”ëª¨ë¦¬ ë‚´ ë¬¸ìì—´ ë²„í¼ ìƒì„±
        writer = csv.writer(output)
        writer.writerow(columns)    # í—¤ë” í–‰ ì‘ì„±
        writer.writerows(rows)      # ë°ì´í„° í–‰ë“¤ ì‘ì„±
        csv_content = output.getvalue()
        output.close()
        return csv_content


    def start_db_sf(self, ex_id):
        """
        Snowflake ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹œì‘
        
        Args:
            ex_id (str): ì˜ˆì œ ID (ì—°ê²° ì‹ë³„ìë¡œ ì‚¬ìš©)
        """
        # ì´ë¯¸ ì—°ê²°ëœ ê²½ìš° ìƒˆë¡œ ì—°ê²°í•˜ì§€ ì•ŠìŒ
        if ex_id not in self.conns.keys():
            # snowflake_credential.json íŒŒì¼ì—ì„œ ì¸ì¦ ì •ë³´ ë¡œë“œ
            snowflake_credential = json.load(open("./snowflake_credential.json"))
            self.conns[ex_id] = snowflake.connector.connect(**snowflake_credential)


    def close_db(self):
        """
        ëª¨ë“  ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¢…ë£Œ
        - ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€ë¥¼ ìœ„í•´ ëª¨ë“  ì—°ê²°ì„ ì•ˆì „í•˜ê²Œ ì¢…ë£Œ
        """
        # print("Close DB")
        for key, conn in list(self.conns.items()):
            try:
                if conn:
                    conn.close()
                    # print(f"Connection {key} closed.")
                    del self.conns[key]  # ì—°ê²° ë”•ì…”ë„ˆë¦¬ì—ì„œ ì œê±°
            except Exception as e:
                print(f"When closing DB for {key}: {e}")

            
    def exec_sql_sf(self, sql_query, save_path, max_len, ex_id):
        """
        Snowflakeì—ì„œ SQL ì¿¼ë¦¬ ì‹¤í–‰
        
        Args:
            sql_query (str): ì‹¤í–‰í•  SQL ì¿¼ë¦¬
            save_path (str): ê²°ê³¼ë¥¼ ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
            max_len (int): ê²°ê³¼ ë°ì´í„°ì˜ ìµœëŒ€ ê¸¸ì´
            ex_id (str): ì˜ˆì œ ID (ì—°ê²° ì‹ë³„ì)
            
        Returns:
            str or int: ì„±ê³µ ì‹œ CSV ë°ì´í„° ë˜ëŠ” 0, ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë©”ì‹œì§€
        """
        with self.conns[ex_id].cursor() as cursor:
            try:
                cursor.execute(sql_query)
                column_info = cursor.description
                rows = self.get_rows(cursor, max_len)
                columns = [desc[0] for desc in column_info]
            except Exception as e:
                return "##ERROR##"+str(e)

        if not rows:
            return "No data found for the specified query.\n"
        else:
            csv_content = self.get_csv(columns, rows) # csv í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            if save_path:
                # íŒŒì¼ë¡œ ì €ì¥
                with open(save_path, 'w', newline='', encoding='utf-8') as f:
                    f.write(csv_content)
                return 0
            else:
                # ë¬¸ìì—´ë¡œ ë°˜í™˜ (ê¸¸ì´ ì œí•œ ì ìš©)
                return hard_cut(csv_content, max_len)


    def execute_sql_api(self, sql_query, ex_id, save_path=None, api="sqlite", max_len=30000, sqlite_path=None, timeout=300):
        """
        ë°ì´í„°ë² ì´ìŠ¤ ì¢…ë¥˜ì— ë”°ë¼ ì ì ˆí•œ SQL ì‹¤í–‰ í•¨ìˆ˜ í˜¸ì¶œ
        
        Args:
            sql_query (str): ì‹¤í–‰í•  SQL ì¿¼ë¦¬
            ex_id (str): ì˜ˆì œ ID
            save_path (str, optional): ê²°ê³¼ë¥¼ ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
            api (str): ë°ì´í„°ë² ì´ìŠ¤ ì¢…ë¥˜ ("sqlite", "snowflake", "bigquery")
            max_len (int): ê²°ê³¼ ë°ì´í„°ì˜ ìµœëŒ€ ê¸¸ì´
            sqlite_path (str, optional): SQLite íŒŒì¼ ê²½ë¡œ
            timeout (int): íƒ€ì„ì•„ì›ƒ ì‹œê°„ (ì´ˆ)
            
        Returns:
            str or dict: ì„±ê³µ ì‹œ ê²°ê³¼ ë°ì´í„°, ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ì •ë³´
        """
        if api == "bigquery":
            result = self.exec_sql_bq(sql_query, save_path, max_len)

        elif api == "snowflake":
            # 1. Snowflake ì—°ê²° í™•ì¸
            if ex_id not in self.conns.keys():
                self.start_db_sf(ex_id)
            # 2. SQL ì‹¤í–‰
            result = self.exec_sql_sf(sql_query, save_path, max_len, ex_id)
            
        elif api == "sqlite":
            # 1. SQLite ì—°ê²° í™•ì¸
            if sqlite_path not in self.conns.keys():
                self.start_db_sqlite(sqlite_path)
            # 2. íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬ì™€ í•¨ê»˜ SQL ì‹¤í–‰
            result = self.execute_sqlite_with_timeout(sql_query, save_path, max_len, sqlite_path, timeout=300)
            # result = self.exec_sql_sqlite(sql_query, save_path, max_len, sqlite_path)

        # ì—ëŸ¬ ì²˜ë¦¬
        if "##ERROR##" in str(result):
            return {"status": "error", "error_msg": str(result)}
        else:
            return str(result)


















                
    # ì£¼ì„ ì²˜ë¦¬ëœ ìŠ¤ë ˆë”© ë°©ì‹ì˜ íƒ€ì„ì•„ì›ƒ êµ¬í˜„ (ì°¸ê³ ìš©)
    # def execute_sqlite_with_timeout(self, sql_query, save_path, max_len, sqlite_path, timeout=300):
    #     """
    #     SQLite ì¿¼ë¦¬ë¥¼ íƒ€ì„ì•„ì›ƒê³¼ í•¨ê»˜ ì‹¤í–‰ (ìŠ¤ë ˆë”© ì‚¬ìš©)
    #     - ë©€í‹°í”„ë¡œì„¸ì‹± ë°©ì‹ë³´ë‹¤ ê°€ë²¼ìš°ë‚˜ GIL ì œí•œìœ¼ë¡œ ì¸í•´ ì‹¤ì œ íƒ€ì„ì•„ì›ƒì´ ì–´ë ¤ìš¸ ìˆ˜ ìˆìŒ
    #     """
    #     result_holder = {"result": None}

    #     def target():
    #         try:
    #             result_holder["result"] = self.exec_sql_sqlite(sql_query, save_path, max_len, sqlite_path)
    #         except Exception as e:
    #             result_holder["result"] = {"status": "error", "error_msg": str(e)}

    #     thread = threading.Thread(target=target)
    #     thread.start()
    #     thread.join(timeout)

    #     if thread.is_alive():
    #         print(f"##ERROR## {sql_query} Timed out")
    #         return {"status": "error", "error_msg": f"##ERROR## {sql_query} Timed out\n"}
    #     else:
    #         return str(result_holder["result"])

    ######################### Snowflake ì™¸ ë°ì´í„°ë² ì´ìŠ¤ ê´€ë ¨ í•¨ìˆ˜ #########################
    def start_db_sqlite(self, sqlite_path):
        """
        SQLite ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹œì‘
        
        Args:
            sqlite_path (str): SQLite ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ ê²½ë¡œ
        """
        # ì´ë¯¸ ì—°ê²°ëœ ê²½ìš° ìƒˆë¡œ ì—°ê²°í•˜ì§€ ì•ŠìŒ
        if sqlite_path not in self.conns:
            # ì½ê¸° ì „ìš© ëª¨ë“œë¡œ SQLite ì—°ê²°
            uri = f"file:{sqlite_path}?mode=ro"
            conn = sqlite3.connect(uri, uri=True, check_same_thread=False)
            self.conns[sqlite_path] = conn
            # print(f"sqlite_path: {sqlite_path}, (self.conns): {self.conns.keys()}")

    def exec_sql_sqlite(self, sql_query, save_path=None, max_len=30000, sqlite_path=None):
        """
        SQLiteì—ì„œ SQL ì¿¼ë¦¬ ì‹¤í–‰
        
        Args:
            sql_query (str): ì‹¤í–‰í•  SQL ì¿¼ë¦¬
            save_path (str, optional): ê²°ê³¼ë¥¼ ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
            max_len (int): ê²°ê³¼ ë°ì´í„°ì˜ ìµœëŒ€ ê¸¸ì´
            sqlite_path (str): SQLite ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            str or int: ì„±ê³µ ì‹œ CSV ë°ì´í„° ë˜ëŠ” 0, ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë©”ì‹œì§€
        """
        cursor = self.conns[sqlite_path].cursor()
        try:
            cursor.execute(sql_query)
            column_info = cursor.description    # ì»¬ëŸ¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            rows = self.get_rows(cursor, max_len)
            columns = [desc[0] for desc in column_info]  # ì»¬ëŸ¼ëª… ì¶”ì¶œ
        except Exception as e:
            return "##ERROR##"+str(e)
        finally:
            try:
                cursor.close()
            except Exception as e:
                print("Failed to close cursor:", e)

        if not rows:
            return "No data found for the specified query.\n"
        else:
            csv_content = self.get_csv(columns, rows)
            if save_path:
                # íŒŒì¼ë¡œ ì €ì¥
                with open(save_path, 'w', newline='', encoding='utf-8') as f:
                    f.write(csv_content)
                return 0
            else:
                # ë¬¸ìì—´ë¡œ ë°˜í™˜ (ê¸¸ì´ ì œí•œ ì ìš©)
                return hard_cut(csv_content, max_len)
            
    def exec_sql_bq(self, sql_query, save_path, max_len):
        """
        BigQueryì—ì„œ SQL ì¿¼ë¦¬ ì‹¤í–‰
        
        Args:
            sql_query (str): ì‹¤í–‰í•  SQL ì¿¼ë¦¬
            save_path (str): ê²°ê³¼ë¥¼ ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
            max_len (int): ê²°ê³¼ ë°ì´í„°ì˜ ìµœëŒ€ ê¸¸ì´
            
        Returns:
            str or int: ì„±ê³µ ì‹œ CSV ë°ì´í„° ë˜ëŠ” 0, ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë©”ì‹œì§€
        """
        # BigQuery ì¸ì¦ ì •ë³´ ë¡œë“œ
        bigquery_credential = service_account.Credentials.from_service_account_file("./bigquery_credential.json")
        client = bigquery.Client(credentials=bigquery_credential, project=bigquery_credential.project_id)
        
        query_job = client.query(sql_query)
        try:
            result_iterator = query_job.result()
        except Exception as e:
            return "##ERROR##"+str(e)
            
        # ê²°ê³¼ í–‰ë“¤ì„ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ìˆ˜ì§‘
        rows = []
        current_len = 0
        for row in result_iterator:
            if current_len > max_len:
                break
            current_len += len(str(dict(row)))
            rows.append(dict(row))
            
        df = pd.DataFrame(rows)
        
        # ê²°ê³¼ê°€ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
        if df.empty:
            return "No data found for the specified query.\n"
        else:
            # ì €ì¥ ë˜ëŠ” ë°˜í™˜
            if save_path:
                df.to_csv(f"{save_path}", index=False)
                return 0
            else:
                return hard_cut(df.to_csv(index=False), max_len)
            
    def execute_sqlite_with_timeout(self, sql_query, save_path, max_len, sqlite_path, timeout=300):
        """
        SQLite ì¿¼ë¦¬ë¥¼ íƒ€ì„ì•„ì›ƒê³¼ í•¨ê»˜ ì‹¤í–‰ (ë©€í‹°í”„ë¡œì„¸ì‹± ì‚¬ìš©)
        - ì˜¤ë˜ ê±¸ë¦¬ëŠ” ì¿¼ë¦¬ê°€ ë¬´í•œì • ì‹¤í–‰ë˜ëŠ” ê²ƒì„ ë°©ì§€
        
        Args:
            sql_query (str): ì‹¤í–‰í•  SQL ì¿¼ë¦¬
            save_path (str): ê²°ê³¼ë¥¼ ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
            max_len (int): ê²°ê³¼ ë°ì´í„°ì˜ ìµœëŒ€ ê¸¸ì´
            sqlite_path (str): SQLite íŒŒì¼ ê²½ë¡œ
            timeout (int): íƒ€ì„ì•„ì›ƒ ì‹œê°„ (ì´ˆ, ê¸°ë³¸ê°’: 300ì´ˆ)
            
        Returns:
            str or dict: ì„±ê³µ ì‹œ ê²°ê³¼ ë°ì´í„°, íƒ€ì„ì•„ì›ƒ ì‹œ ì—ëŸ¬ ì •ë³´
        """
        def target(q):
            """
            ë³„ë„ í”„ë¡œì„¸ìŠ¤ì—ì„œ ì‹¤í–‰ë  í•¨ìˆ˜
            - SQL ì‹¤í–‰ ê²°ê³¼ë¥¼ íì— ì €ì¥
            """
            result = self.exec_sql_sqlite(sql_query, save_path, max_len, sqlite_path)
            q.put(str(result))
            
        q = Queue()  # í”„ë¡œì„¸ìŠ¤ ê°„ í†µì‹ ì„ ìœ„í•œ í
        p = Process(target=target, args=(q,))
        p.start()

        # ì§€ì •ëœ ì‹œê°„ë§Œí¼ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ ëŒ€ê¸°
        p.join(timeout)
        
        if p.is_alive():
            # íƒ€ì„ì•„ì›ƒ ë°œìƒ ì‹œ í”„ë¡œì„¸ìŠ¤ ê°•ì œ ì¢…ë£Œ
            try:
                p.terminate()
                p.join(timeout=2)
                if p.is_alive():
                    print("Terminate failed, forcing kill.")
                    p.kill()
                    p.join()
            except Exception as e:
                print(f"Error when stopping process: {e}")
            print(f"##ERROR## {sql_query} Timed out")
            return {"status": "error", "error_msg": f"##ERROR## {sql_query} Timed out\n"}
        else:
            # ì •ìƒ ì™„ë£Œ ì‹œ ê²°ê³¼ ë°˜í™˜
            if not q.empty():
                result = q.get()
                return result
            else:
                raise RuntimeError("Process p dead")