import os
import argparse
import glob
from utils import get_table_info, initialize_logger, get_dictionary, get_sqlite_path
from agent import REFORCE
from chat import GPTChat
from prompt import Prompts
import threading, concurrent
from sql import SqlEnv
import time
import json
import re

def execute(question, table_info, args, csv_save_path, log_save_path, sql_save_path, search_directory, format_csv, sql_data):
    """
    """
    print(f"      ğŸ”„ SQL ìƒì„± ì‹œì‘: {sql_data}/{sql_save_path}")
    
    db_id = None
    if full_db_id:
        db_id = full_db_id[sql_data]

    # 1. SQL í™˜ê²½ ì´ˆê¸°í™”
    sql_env = SqlEnv()
    # revote: execute sql if no csv
    if os.path.exists(os.path.join(search_directory, sql_save_path)) and not os.path.exists(os.path.join(search_directory, csv_save_path)) and args.revote:
        with open(os.path.join(search_directory, sql_save_path)) as f:
            sql = f.read()
        sql_env.execute_sql_api(sql, sql_data, os.path.join(search_directory, csv_save_path), sqlite_path=get_sqlite_path(args.db_path, sql_data, db_id, args.task))

    if args.rerun:
        if os.path.exists(os.path.join(search_directory, sql_save_path)):
            print(f"        â­ï¸  Rerun ëª¨ë“œ: ê¸°ì¡´ ê²°ê³¼ ì¡´ì¬, ìŠ¤í‚µ")
            return
        else:
            print(f"        ğŸ”„ Rerun ëª¨ë“œ: ìƒˆë¡œ ìƒì„± í•„ìš”")
    # if log.log exists, pass
    elif os.path.exists(os.path.join(search_directory, log_save_path)):
        print(f"        â­ï¸  ë¡œê·¸ íŒŒì¼ ì¡´ì¬, ìŠ¤í‚µ")
        return

    # remove files
    self_files = glob.glob(os.path.join(search_directory, f'*{log_save_path}*'))
    for self_file in self_files:
        os.remove(self_file)

    # log
    log_file_path = os.path.join(search_directory, log_save_path)
    logger = initialize_logger(log_file_path)
    if format_csv:
        logger.info("[ë‹µë³€ í˜•ì‹]\n" + format_csv + "\n[ë‹µë³€ í˜•ì‹]")
    table_struct = table_info[table_info.find("í…Œì´ë¸” êµ¬ì¡° ì •ë³´"):]

    # 2. GPT ì±„íŒ… ì„¸ì…˜ ì´ˆê¸°í™”
    print(f"        ğŸ¤– GPT ì„¸ì…˜ ì´ˆê¸°í™” ì¤‘...")
    chat_session_ex = None # Column Explorationìš© ì±„íŒ… ì„¸ì…˜
    chat_session = None    # ìµœì¢… SQL Generationìš© ì±„íŒ… ì„¸ì…˜
    if args.do_column_exploration:
        chat_session_ex = GPTChat(args.azure, args.column_exploration_model, temperature=args.temperature)
        print(f"        ğŸ” Column Exploration ì„¸ì…˜ ì¤€ë¹„ ì™„ë£Œ: {args.column_exploration_model}")
    if args.generation_model:
        chat_session = GPTChat(args.azure, args.generation_model, temperature=args.temperature)
        print(f"        âš¡ SQL Generation ì„¸ì…˜ ì¤€ë¹„ ì™„ë£Œ: {args.generation_model}")

    # 3. REFORCE ì—ì´ì „íŠ¸ ìƒì„±
    agent = REFORCE(
        args.db_path,      # "examples_fnf" 
        sql_data,          # "fnf001"
        search_directory,  # "output/o3-fnf-no-exploration-log-20241215-143022/fnf001"
        prompt_all,        # Prompts() ì¸ìŠ¤í„´ìŠ¤
        sql_env,           # SQL ì‹¤í–‰ í™˜ê²½
        chat_session_ex,   # Column Explorationìš© GPT ì„¸ì…˜
        chat_session,      # SQL Generationìš© GPT ì„¸ì…˜
        sql_data+'/'+log_save_path,  # ë¡œê·¸ ì‹ë³„ì
        db_id,             # ë°ì´í„°ë² ì´ìŠ¤ ID
        task=args.task     # íƒœìŠ¤í¬ ì •ë³´
    )

    # do_column_exploration
    pre_info, response_pre_txt = None, None
    # 4. ì»¬ëŸ¼ íƒìƒ‰ ìˆ˜í–‰ (ì˜µì…˜)
    if args.do_column_exploration:
        print(f"        ğŸ” Column Exploration ì‹œì‘...")
        pre_info, response_pre_txt, max_try = agent.exploration(question, table_struct, table_info, logger)
        if max_try <= 0:
            print(f"        âŒ Column Exploration ì‹¤íŒ¨: {sql_data+'/'+log_save_path} ì¤€ë¹„ ë¶€ì¡±, ê±´ë„ˆëœ€")
            return
        print(f"        âœ… Column Exploration ì™„ë£Œ: ì±„íŒ… ì„¸ì…˜ ê¸¸ì´ {chat_session_ex.get_message_len()}")

    csv_save_path = os.path.join(search_directory, csv_save_path)
    sql_save_path = os.path.join(search_directory, sql_save_path)

    # 5. Self-refinement ë˜ëŠ” ë‹¨ìˆœ ìƒì„±
    if args.do_self_refinement:
        print(f"        ğŸ”„ Self-refinement ì‹œì‘ (ìµœëŒ€ {args.max_iter}íšŒ ë°˜ë³µ)...")
        agent.self_refine(args, logger, question, format_csv, table_struct, table_info, response_pre_txt, pre_info, csv_save_path, sql_save_path, task=args.task)
        print(f"        âœ… Self-refinement ì™„ë£Œ")
    elif args.generation_model:
        print(f"        ğŸ¯ ë‹¨ìˆœ SQL Generation ì‹œì‘...")
        agent.gen(args, logger, question, format_csv, table_struct, table_info, response_pre_txt, pre_info, csv_save_path, sql_save_path, task=args.task)
        print(f"        âœ… SQL Generation ì™„ë£Œ")
    
    if args.generation_model:
        agent.sql_env.close_db()
    
    print(f"      âœ… SQL Generation ì™„ë£Œ: {sql_data}/{sql_save_path}")

def main(args):
    print("=" * 80)
    print("ğŸš€ ReFoRCE ë©”ì¸ í”„ë¡œì„¸ìŠ¤ ì‹œì‘")
    print("=" * 80)
    print(f"ğŸ“Š ì²˜ë¦¬í•  ì¸ìŠ¤í„´ìŠ¤ ìˆ˜: {len(dictionaries)}ê°œ")
    print(f"ğŸ”§ ë³‘ë ¬ num_workers: {args.num_workers}ê°œ")
    print(f"ğŸ¯ Task: {args.task}")
    print(f"ğŸ“‚ ì¶œë ¥ ê²½ë¡œ: {args.output_path}")
    print()
    
    # Use ThreadPoolExecutor to process each sql_data in parallel
    with concurrent.futures.ThreadPoolExecutor(max_workers=args.num_workers) as executor:
        list(executor.map(process_sql_data, dictionaries))

    print()
    print("=" * 80)
    print("ğŸ‰ ëª¨ë“  ì¸ìŠ¤í„´ìŠ¤ ì²˜ë¦¬ ì™„ë£Œ!")
    print("=" * 80)

def process_sql_data(sql_data): # sql_data = "sf_bq070"
    """
    ê°œë³„ ì¸ìŠ¤í„´ìŠ¤ ì²˜ë¦¬ í•¨ìˆ˜

    Args:
        sql_data (str): ì²˜ë¦¬í•  ì¸ìŠ¤í„´ìŠ¤ ID

    Returns:
        None
    """
    # ì´ˆê¸° ì„¤ì •
    start_time = time.time()

    print(f"ğŸ“‹ [{sql_data}] ì¸ìŠ¤í„´ìŠ¤ ì²˜ë¦¬ ì‹œì‘")

    question = task_dict[sql_data] # "Find top 5 customers..."
    search_directory = os.path.join(args.output_path, sql_data) # "output/o3-snow-log/sf_bq070"

    # Create agent object
    agent_format = REFORCE(args.db_path, sql_data, search_directory, prompt_all)
    
    # Create the directory if it does not exist
    if not os.path.exists(search_directory):
        os.makedirs(search_directory)
        print(f"    ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±: {search_directory}")

    # Skip processing if results already exist and overwrite is not allowed
    if os.path.exists(agent_format.complete_sql_save_path) and not args.revote:
        print(f"    â­ï¸  ìµœì¢… ê²°ê³¼ ì¡´ì¬, ìŠ¤í‚µ: {agent_format.complete_sql_save_path}")
        return
    
    if args.overwrite_unfinished:
        if not os.path.exists(agent_format.complete_sql_save_path):
            print(f"    ğŸ—‘ï¸  ë¯¸ì™„ë£Œ íŒŒì¼ë“¤ ì •ë¦¬ ì¤‘...")
            for filename in os.listdir(search_directory):
                filepath = os.path.join(search_directory, filename)
                if os.path.isfile(filepath):
                    os.remove(filepath)
            print(f"    âœ… ë¯¸ì™„ë£Œ íŒŒì¼ë“¤ ì •ë¦¬ ì™„ë£Œ")
        else:
            print(f"    â­ï¸  ì™„ë£Œëœ ê²°ê³¼ ì¡´ì¬, ìŠ¤í‚µ")
            return

    # Ensure the search directory exists (in case it was removed)
    if not os.path.exists(search_directory):
        os.makedirs(search_directory)

    # # sqlite task
    # if args.subtask == "sqlite":
    #     if not sql_data.startswith("local"):
    #         print(f"    â­ï¸  SQLite ì„œë¸ŒíƒœìŠ¤í¬: localì´ ì•„ë‹Œ ì¸ìŠ¤í„´ìŠ¤ ìŠ¤í‚µ")
    #         return

    # # Get BIRD gold res
    # if args.task == "BIRD":
    #     gold_pth = os.path.join(args.BIRD_gold_result_path, sql_data+".csv")
    #     if not os.path.exists(gold_pth):
    #         print(f"    ğŸ† BIRD ê³¨ë“œ ê²°ê³¼ ìƒì„± ì¤‘...")
    #         sql_env = SqlEnv()
    #         res = sql_env.execute_sql_api(full_gold_sql[sql_data], sql_data, gold_pth, sqlite_path=get_sqlite_path(args.db_path, sql_data, full_db_id[sql_data], args.task), timeout=1200)
    #         assert res == "0", (sql_data, res)
    #         print(f"    âœ… BIRD ê³¨ë“œ ê²°ê³¼ ìƒì„± ì™„ë£Œ")

    # Get table information
    print(f"    ğŸ“Š í…Œì´ë¸” ì •ë³´ ë¡œë“œ ì¤‘...")
    table_info = get_table_info(args.db_path, sql_data, agent_format.api, clear_des=True, full_tb_info=full_tb_info)
    if len(table_info) > 300000:
        print(f"    âš ï¸  í…Œì´ë¸” ì •ë³´ í¬ê¸° ì´ˆê³¼: {len(table_info):,} bytes, ë°˜í™˜")
        return
    print(f"    âœ… í…Œì´ë¸” ì •ë³´ ë¡œë“œ ì™„ë£Œ: {len(table_info):,} bytes")

    # Format restriction ì²˜ë¦¬
    format_csv = None
    if args.do_format_restriction:
        print(f"    ğŸ“ ë‹µë³€ í˜•ì‹ ì œí•œ ì²˜ë¦¬ ì¤‘...")
        if args.use_gold_format:
            csv_pth = os.path.join("../../spider2-lite/evaluation_suite/gold/exec_result", sql_data+".csv")
            if not os.path.exists(csv_pth):
                csv_pth = csv_pth.replace(".csv", "_a.csv")
            with open(csv_pth) as f:
                format_csv = "```sql\n"+f.read().split("\n")[0]+"\n```"
            print(f"    âœ… ê³¨ë“œ í˜•ì‹ ë¡œë“œ ì™„ë£Œ")
        else:
            # Initialize sessions at the beginning of each thread
            chat_session_format = GPTChat(args.azure, args.format_model, temperature=args.temperature)
            # Format answer and update the pre-chat session
            format_csv = agent_format.format_answer(question, chat_session_format)
            print(f"    âœ… í˜•ì‹ ìƒì„± ì™„ë£Œ")

    # íˆ¬í‘œ ëª¨ë“œ vs ë‹¨ì¼ ëª¨ë“œ ì²˜ë¦¬
    if args.do_vote:
        print(f"    ğŸ—³ï¸  íˆ¬í‘œ ëª¨ë“œ ì‹œì‘ ({args.num_votes}ë²ˆ ì‹œë„)")
        num_votes = args.num_votes
        sql_paths = {}
        threads = []

        for i in range(num_votes):
            csv_save_pathi = str(i) + agent_format.csv_save_name    # "0result.csv", "1result.csv", "2result.csv" (ê°ê° ì²« ë²ˆì§¸, ë‘ ë²ˆì§¸, ì„¸ ë²ˆì§¸ ì‹œë„)
            log_pathi = str(i) + agent_format.log_save_name         # "0log.log", "1log.log", "2log.log"
            sql_save_pathi = str(i) + agent_format.sql_save_name    # "0result.sql", "1result.sql", "2result.sql"
            sql_paths[sql_save_pathi] = csv_save_pathi 

            # ê°ê°ì„ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
            thread = threading.Thread(
                target=execute,
                args=(
                    question, table_info, args,
                    csv_save_pathi, log_pathi, sql_save_pathi,
                    search_directory, format_csv, sql_data
                )
            )
            threads.append(thread)
            thread.start()

        print(f"    â³ {num_votes}ê°œ ìŠ¤ë ˆë“œ ì‹¤í–‰ ëŒ€ê¸° ì¤‘...")
        # wait
        for thread in threads:
            thread.join()
        print(f"    âœ… ëª¨ë“  ìŠ¤ë ˆë“œ ì‹¤í–‰ ì™„ë£Œ")
        
        # ì¬íˆ¬í‘œ ì²˜ë¦¬
        if args.revote:
            print(f"    ğŸ”„ ì¬íˆ¬í‘œ ëª¨ë“œ: ê¸°ì¡´ ê²°ê³¼ ì œê±°")
            if "result.sql" in os.listdir(search_directory):
                print(f"        ğŸ—‘ï¸  ê¸°ì¡´ result.sql ì œê±°: {os.path.join(search_directory, 'result.sql')}")
                os.remove(os.path.join(search_directory, "result.sql"))
            if "result.csv" in os.listdir(search_directory):
                print(f"        ğŸ—‘ï¸  ê¸°ì¡´ result.csv ì œê±°: {os.path.join(search_directory, 'result.csv')}")
                os.remove(os.path.join(search_directory, "result.csv"))
        
        # íˆ¬í‘œ ê²°ê³¼ ì²˜ë¦¬
        if "result.sql" not in os.listdir(search_directory):
            sql_files = [f for f in os.listdir(search_directory) if f.endswith('.sql') and os.path.isfile(os.path.join(search_directory, f))]
            if sql_files:
                print(f"    ğŸ—³ï¸  íˆ¬í‘œ ì‹œì‘: {len(sql_files)}ê°œ SQL íŒŒì¼ ë°œê²¬")
                print(f"        ğŸ“ SQL íŒŒì¼ë“¤: {sql_files}")
                # After all processes have completed, perform the vote result
                agent_format.vote_result(search_directory, args, sql_paths, table_info, question)
                
                # íˆ¬í‘œ ê²°ê³¼ í™•ì¸
                if os.path.exists(os.path.join(search_directory, "result.sql")):
                    print(f"    âœ… íˆ¬í‘œ ì™„ë£Œ: result.sql ìƒì„±ë¨")
                else:
                    print(f"    âŒ íˆ¬í‘œ ì‹¤íŒ¨: result.sql ìƒì„±ë˜ì§€ ì•ŠìŒ")
            else:
                print(f"    âŒ íˆ¬í‘œ ë¶ˆê°€: SQL íŒŒì¼ì´ ì—†ìŒ")
    else:
        print(f"    ğŸ¯ ë‹¨ì¼ ëª¨ë“œ ì‹¤í–‰")
        # Directly execute the task
        execute(
            question, table_info, args,
            agent_format.csv_save_name, agent_format.log_save_name, agent_format.sql_save_name,
            search_directory, format_csv, sql_data
        )

    elapsed_time = int((time.time() - start_time) // 60)
    print(f"âœ… [{sql_data}] ì²˜ë¦¬ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {elapsed_time}ë¶„)")
    print()

if __name__ == '__main__':
    # 1-1. ì¸ì íŒŒì‹±
    parser = argparse.ArgumentParser()
    parser.add_argument('--task', type=str, default="snow", choices=["snow", "lite", "BIRD", "fnf"],)
    parser.add_argument('--subtask', type=str, default=None, choices=["sqlite"])
    parser.add_argument('--db_path', type=str, default=None)
    parser.add_argument('--output_path', type=str, default="output/o3-snow-log")

    parser.add_argument('--do_format_restriction', action="store_true")
    parser.add_argument('--use_gold_format', action="store_true")
    parser.add_argument('--format_model', type=str, default="o3")

    parser.add_argument('--do_column_exploration', action="store_true")
    parser.add_argument('--column_exploration_model', type=str, default="o3")    

    parser.add_argument('--do_self_refinement', action="store_true")
    parser.add_argument('--do_self_consistency', action="store_true")
    parser.add_argument('--generation_model', type=str, default=None)
    parser.add_argument('--azure', action="store_true")

    parser.add_argument('--max_iter', type=int, default=5)
    parser.add_argument('--temperature', type=float, default=1)
    parser.add_argument('--early_stop', action="store_true")

    parser.add_argument('--do_vote', action="store_true")
    parser.add_argument('--revote', action="store_true")
    parser.add_argument('--num_votes', type=int, default=3)
    parser.add_argument('--random_vote_for_tie', action="store_true")
    parser.add_argument('--model_vote', type=str, default=None)
    parser.add_argument('--final_choose', action="store_true")

    parser.add_argument('--save_all_results', action="store_true")
    parser.add_argument('--rerun', action="store_true")
    parser.add_argument('--overwrite_unfinished', action="store_true")
    parser.add_argument('--num_workers', type=int, default=16)

    parser.add_argument('--omnisql_format_pth', type=str, default=None)
    parser.add_argument('--BIRD_gold_result_path', type=str, default="../../data/BIRD/gold_result")

    args = parser.parse_args()

    # 1-2. ì „ì—­ ë³€ìˆ˜ ì´ˆê¸°í™”
    prompt_all = Prompts()  # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì½”ë“œ
    full_db_id = {}         # ë°ì´í„°ë² ì´ìŠ¤ ID ë§¤í•‘
    full_tb_info = {}       # í…Œì´ë¸” ì •ë³´ ìºì‹œ

    full_gold_sql = {}      # ê³¨ë“œ SQL (BIRD íƒœìŠ¤í¬ìš©)

    # # 2-1. íŠ¹ìˆ˜ í˜•ì‹ íŒŒì¼ ì²˜ë¦¬ (omnisql_format_pthê°€ ìˆëŠ” ê²½ìš°)
    # if args.omnisql_format_pth:
    #     # SQLite ë˜ëŠ” BIRD íƒœìŠ¤í¬ìš© íŠ¹ë³„ ì²˜ë¦¬
        
    #     # SQLite íƒœìŠ¤í¬ìš© ì²˜ë¦¬
    #     if args.subtask == "sqlite":
    #         with open(args.omnisql_format_pth) as f:
    #             data = json.load(f)
    #         dictionaries = []
    #         task_dict = {}
    #         full_tb_info = {}
            
    #         for example in data:
    #             if example["instance_id"].startswith("local"):
    #                 dictionaries.append(example["instance_id"])
    #                 task_dict[example["instance_id"]] = example["question"]
    #                 full_tb_info[example["instance_id"]] = example["db_desc"]
    #                 full_db_id[example["instance_id"]] = example["db_id"]

    #     # BIRD íƒœìŠ¤í¬ìš© ì²˜ë¦¬
    #     elif args.task == "BIRD":
    #         with open(args.omnisql_format_pth) as f:
    #             data = json.load(f)
    #         dictionaries = []
    #         task_dict = {}
    #         full_tb_info = {}
            
    #         for example in data:
    #             q_id = example["question_id"]
    #             instance_id = f"local_BIRD_{q_id:04d}"
    #             dictionaries.append(instance_id)
    #             task_dict[instance_id] = example["question"]
    #             full_tb_info[instance_id] = example["input_seq"]
    #             full_db_id[instance_id] = example["db_id"]     
    #             full_gold_sql[instance_id] = example["SQL"]                     
    # else:
    #     # ì¼ë°˜ì ì¸ ê²½ìš°: ê¸°ë³¸ ë”•ì…”ë„ˆë¦¬ ë° íƒœìŠ¤í¬ ì •ë³´ ë¡œë“œ
    #     dictionaries, task_dict = get_dictionary(args.db_path, args.task)
    # ì¼ë°˜ì ì¸ ê²½ìš°: ê¸°ë³¸ ë”•ì…”ë„ˆë¦¬ ë° íƒœìŠ¤í¬ ì •ë³´ ë¡œë“œ
    dictionaries, task_dict = get_dictionary(args.db_path, args.task)

    # 2-2. ë©”ì¸ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ (ë³‘ë ¬ ì²˜ë¦¬)
    main(args)